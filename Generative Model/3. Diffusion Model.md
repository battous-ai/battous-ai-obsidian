

# Conclusion

# Math behind
# Reading Notes
- a Markov chain of diffusion steps
	- slowly  add random noise to data
	- learn to reverse the diffusion process to construct desired data sample from the noise
- ![[Pasted image 20240218145712.png]]
- forward diffusion process
	- $\beta_t$: variance scheduler
		- $\beta_t \in (0,1)$
		- $\alpha_t=1-\beta_t$
	- $q(x_t|x_{t-1})=\mathcal{N}(\sqrt{1-\beta_t}x_{t-1}, \beta_tI)$
		- $\mu_{x_t}=\sqrt{\alpha_t}x_{t-1}$  _// by definition_
		- $\sigma_{x_t}=\beta_tI=(1-\alpha_t)I$   _// by definition, has nothing to do with $x_{t-1}$_
	- $x_t \sim \mathcal{N}(\sqrt{\bar{\alpha_t}}x_0,(1-\bar{\alpha_t})I)$
- reverse diffusion process




# 0 Markov chain

A **Markov chain** or **Markov process** is a [stochastic model](https://en.wikipedia.org/wiki/Stochastic_process "Stochastic process") describing a sequence of possible events in which the probability of each event depends **only** on the state attained in the previous event

https://zhuanlan.zhihu.com/p/448575579

# 0.1 Monte Carlo

https://www.cnblogs.com/chenhuabin/p/13252971.html
https://zhuanlan.zhihu.com/p/369099011

# 1 Deep Unsupervised Learning using Nonequilibrium Thermodynamics

Here, we develop an approach that simultane- ously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This ap- proach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model.

Historically, probabilistic models suffer from a tradeoff be- tween two conflicting objectives: tractability and flexibil- ity.